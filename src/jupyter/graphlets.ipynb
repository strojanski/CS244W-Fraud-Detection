{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5472a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import NLLLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abdc95",
   "metadata": {},
   "source": [
    "1. Get edgelists as BLANT inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de0b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2, 50):\n",
    "#     original_edges = f\"../../graphs/tx_graph/tx_transaction_graph_timestamp_{i}.pkl\"\n",
    "\n",
    "#     G = pkl.load(open(original_edges, \"rb\"))\n",
    "#     np.savetxt(f\"edgelists/tx_transaction_graph_timestamp_{i}.el\", list(G.edges()), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a8bb2",
   "metadata": {},
   "source": [
    "2. Graphlet preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e66c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gs = []\n",
    "# graphlets_list = []\n",
    "# for i in range(1, 50):\n",
    "#     Gs.append(pkl.load(open(f\"../../graphs/tx_graph/tx_transaction_graph_timestamp_{i}.pkl\", \"rb\")))\n",
    "#     graphlets = np.loadtxt(f\"graphlets/tx_{i}_dedup_6.graphlets\", dtype=int)\n",
    "#     graphlets_list.append(graphlets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f18364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = pkl.load(open(f\"../../graphs/tx_graph/tx_transaction_graph_timestamp_1.pkl\", \"rb\"))\n",
    "graphlets1 = np.loadtxt(f\"graphlets/tx_1_dedup_6.graphlets\", dtype=int)\n",
    "\n",
    "G2 = pkl.load(open(f\"../../graphs/tx_graph/tx_transaction_graph_timestamp_2.pkl\", \"rb\"))\n",
    "graphlets2 = np.loadtxt(f\"graphlets/tx_2_dedup_6.graphlets\", dtype=int)\n",
    "\n",
    "G3 = pkl.load(open(f\"../../graphs/tx_graph/tx_transaction_graph_timestamp_3.pkl\", \"rb\"))\n",
    "graphlets3 = np.loadtxt(f\"graphlets/tx_3_dedup_6.graphlets\", dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113109a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1, graphlets1 = graphlets1[:, 0], graphlets1[:, 1:]  # Do this after getting unique graphlets to account for orbits\n",
    "ids2, graphlets2 = graphlets2[:, 0], graphlets2[:, 1:]  # Do this after getting unique graphlets to account for orbits\n",
    "ids3, graphlets3 = graphlets3[:, 0], graphlets3[:, 1:]  # Do this after getting unique graphlets to account for orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd7cf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 111, 112)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ids1)), len(set(ids2)), len(set(ids3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d518cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3349993, 2148325, 2090710)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphlets1), len(graphlets2), len(graphlets3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'graphlet_dataset' from 'c:\\\\Users\\\\sebas\\\\one\\\\OneDrive\\\\grive\\\\faks\\\\masters\\\\y2\\\\s1\\\\MLG\\\\MLG\\\\Project\\\\src\\\\jupyter\\\\graphlet_dataset.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import graphlet_dataset  # the module, not the class\n",
    "import random\n",
    "\n",
    "# random.shuffle(graphlets2)\n",
    "\n",
    "train_graphlets = graphlets1\n",
    "val_graphlets = graphlets2\n",
    "test_graphlets = graphlets3[:len(graphlets1)//2]  # Make test set the same size as train set for balanced eval\n",
    "\n",
    "# Reload the module\n",
    "reload(graphlet_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5640784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_graphlet_label(graphlet,G ):\n",
    "    node_classes = [G.nodes[n].get(\"class\", 3) - 1 for n in graphlet]\n",
    "    if 0 in node_classes: \n",
    "        return 0\n",
    "    return max(set(node_classes), key=node_classes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a584820e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({2.0: 1434150, 1.0: 638766, 0: 75409}),\n",
       " Counter({2.0: 1863373, 1.0: 218437, 0: 8900}),\n",
       " Counter({2.0: 1835456, 1.0: 1473413, 0: 41124}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels = [get_single_graphlet_label(g, G2) for g in val_graphlets]\n",
    "test_labels = [get_single_graphlet_label(g, G3) for g in test_graphlets]\n",
    "train_labels = [get_single_graphlet_label(g, G1) for g in train_graphlets]\n",
    "\n",
    "from collections import Counter\n",
    "Counter(val_labels), Counter(test_labels), Counter(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d15f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val vs Test overlap: 0\n",
      "Train vs Val overlap: 0\n",
      "Train vs Test overlap: 0\n"
     ]
    }
   ],
   "source": [
    "val_test   = set(tuple(sorted(g)) for g in val_graphlets)\n",
    "test_test  = set(tuple(sorted(g)) for g in test_graphlets)\n",
    "train_test = set(tuple(sorted(g)) for g in train_graphlets)\n",
    "\n",
    "print(\"Val vs Test overlap:\", len(val_test & test_test))\n",
    "print(\"Train vs Val overlap:\", len(train_test & val_test))\n",
    "print(\"Train vs Test overlap:\", len(train_test & test_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f8b0d",
   "metadata": {},
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb85db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time step', 'Local_feature_1', 'Local_feature_2', 'Local_feature_3', 'Local_feature_4', 'Local_feature_5', 'Local_feature_6', 'Local_feature_7', 'Local_feature_8', 'Local_feature_9', 'Local_feature_10', 'Local_feature_11', 'Local_feature_12', 'Local_feature_13', 'Local_feature_14', 'Local_feature_15', 'Local_feature_16', 'Local_feature_17', 'Local_feature_18', 'Local_feature_19', 'Local_feature_20', 'Local_feature_21', 'Local_feature_22', 'Local_feature_23', 'Local_feature_24', 'Local_feature_25', 'Local_feature_26', 'Local_feature_27', 'Local_feature_28', 'Local_feature_29', 'Local_feature_30', 'Local_feature_31', 'Local_feature_32', 'Local_feature_33', 'Local_feature_34', 'Local_feature_35', 'Local_feature_36', 'Local_feature_37', 'Local_feature_38', 'Local_feature_39', 'Local_feature_40', 'Local_feature_41', 'Local_feature_42', 'Local_feature_43', 'Local_feature_44', 'Local_feature_45', 'Local_feature_46', 'Local_feature_47', 'Local_feature_48', 'Local_feature_49', 'Local_feature_50', 'Local_feature_51', 'Local_feature_52', 'Local_feature_53', 'Local_feature_54', 'Local_feature_55', 'Local_feature_56', 'Local_feature_57', 'Local_feature_58', 'Local_feature_59', 'Local_feature_60', 'Local_feature_61', 'Local_feature_62', 'Local_feature_63', 'Local_feature_64', 'Local_feature_65', 'Local_feature_66', 'Local_feature_67', 'Local_feature_68', 'Local_feature_69', 'Local_feature_70', 'Local_feature_71', 'Local_feature_72', 'Local_feature_73', 'Local_feature_74', 'Local_feature_75', 'Local_feature_76', 'Local_feature_77', 'Local_feature_78', 'Local_feature_79', 'Local_feature_80', 'Local_feature_81', 'Local_feature_82', 'Local_feature_83', 'Local_feature_84', 'Local_feature_85', 'Local_feature_86', 'Local_feature_87', 'Local_feature_88', 'Local_feature_89', 'Local_feature_90', 'Local_feature_91', 'Local_feature_92', 'Local_feature_93', 'Aggregate_feature_1', 'Aggregate_feature_2', 'Aggregate_feature_3', 'Aggregate_feature_4', 'Aggregate_feature_5', 'Aggregate_feature_6', 'Aggregate_feature_7', 'Aggregate_feature_8', 'Aggregate_feature_9', 'Aggregate_feature_10', 'Aggregate_feature_11', 'Aggregate_feature_12', 'Aggregate_feature_13', 'Aggregate_feature_14', 'Aggregate_feature_15', 'Aggregate_feature_16', 'Aggregate_feature_17', 'Aggregate_feature_18', 'Aggregate_feature_19', 'Aggregate_feature_20', 'Aggregate_feature_21', 'Aggregate_feature_22', 'Aggregate_feature_23', 'Aggregate_feature_24', 'Aggregate_feature_25', 'Aggregate_feature_26', 'Aggregate_feature_27', 'Aggregate_feature_28', 'Aggregate_feature_29', 'Aggregate_feature_30', 'Aggregate_feature_31', 'Aggregate_feature_32', 'Aggregate_feature_33', 'Aggregate_feature_34', 'Aggregate_feature_35', 'Aggregate_feature_36', 'Aggregate_feature_37', 'Aggregate_feature_38', 'Aggregate_feature_39', 'Aggregate_feature_40', 'Aggregate_feature_41', 'Aggregate_feature_42', 'Aggregate_feature_43', 'Aggregate_feature_44', 'Aggregate_feature_45', 'Aggregate_feature_46', 'Aggregate_feature_47', 'Aggregate_feature_48', 'Aggregate_feature_49', 'Aggregate_feature_50', 'Aggregate_feature_51', 'Aggregate_feature_52', 'Aggregate_feature_53', 'Aggregate_feature_54', 'Aggregate_feature_55', 'Aggregate_feature_56', 'Aggregate_feature_57', 'Aggregate_feature_58', 'Aggregate_feature_59', 'Aggregate_feature_60', 'Aggregate_feature_61', 'Aggregate_feature_62', 'Aggregate_feature_63', 'Aggregate_feature_64', 'Aggregate_feature_65', 'Aggregate_feature_66', 'Aggregate_feature_67', 'Aggregate_feature_68', 'Aggregate_feature_69', 'Aggregate_feature_70', 'Aggregate_feature_71', 'Aggregate_feature_72', 'in_txs_degree', 'out_txs_degree', 'total_BTC', 'fees', 'size', 'num_input_addresses', 'num_output_addresses', 'in_BTC_min', 'in_BTC_max', 'in_BTC_mean', 'in_BTC_median', 'in_BTC_total', 'out_BTC_min', 'out_BTC_max', 'out_BTC_mean', 'out_BTC_median', 'out_BTC_total']\n",
      "['Time step', 'Local_feature_1', 'Local_feature_2', 'Local_feature_3', 'Local_feature_4', 'Local_feature_5', 'Local_feature_6', 'Local_feature_7', 'Local_feature_8', 'Local_feature_9', 'Local_feature_10', 'Local_feature_11', 'Local_feature_12', 'Local_feature_13', 'Local_feature_14', 'Local_feature_15', 'Local_feature_16', 'Local_feature_17', 'Local_feature_18', 'Local_feature_19', 'Local_feature_20', 'Local_feature_21', 'Local_feature_22', 'Local_feature_23', 'Local_feature_24', 'Local_feature_25', 'Local_feature_26', 'Local_feature_27', 'Local_feature_28', 'Local_feature_29', 'Local_feature_30', 'Local_feature_31', 'Local_feature_32', 'Local_feature_33', 'Local_feature_34', 'Local_feature_35', 'Local_feature_36', 'Local_feature_37', 'Local_feature_38', 'Local_feature_39', 'Local_feature_40', 'Local_feature_41', 'Local_feature_42', 'Local_feature_43', 'Local_feature_44', 'Local_feature_45', 'Local_feature_46', 'Local_feature_47', 'Local_feature_48', 'Local_feature_49', 'Local_feature_50', 'Local_feature_51', 'Local_feature_52', 'Local_feature_53', 'Local_feature_54', 'Local_feature_55', 'Local_feature_56', 'Local_feature_57', 'Local_feature_58', 'Local_feature_59', 'Local_feature_60', 'Local_feature_61', 'Local_feature_62', 'Local_feature_63', 'Local_feature_64', 'Local_feature_65', 'Local_feature_66', 'Local_feature_67', 'Local_feature_68', 'Local_feature_69', 'Local_feature_70', 'Local_feature_71', 'Local_feature_72', 'Local_feature_73', 'Local_feature_74', 'Local_feature_75', 'Local_feature_76', 'Local_feature_77', 'Local_feature_78', 'Local_feature_79', 'Local_feature_80', 'Local_feature_81', 'Local_feature_82', 'Local_feature_83', 'Local_feature_84', 'Local_feature_85', 'Local_feature_86', 'Local_feature_87', 'Local_feature_88', 'Local_feature_89', 'Local_feature_90', 'Local_feature_91', 'Local_feature_92', 'Local_feature_93', 'Aggregate_feature_1', 'Aggregate_feature_2', 'Aggregate_feature_3', 'Aggregate_feature_4', 'Aggregate_feature_5', 'Aggregate_feature_6', 'Aggregate_feature_7', 'Aggregate_feature_8', 'Aggregate_feature_9', 'Aggregate_feature_10', 'Aggregate_feature_11', 'Aggregate_feature_12', 'Aggregate_feature_13', 'Aggregate_feature_14', 'Aggregate_feature_15', 'Aggregate_feature_16', 'Aggregate_feature_17', 'Aggregate_feature_18', 'Aggregate_feature_19', 'Aggregate_feature_20', 'Aggregate_feature_21', 'Aggregate_feature_22', 'Aggregate_feature_23', 'Aggregate_feature_24', 'Aggregate_feature_25', 'Aggregate_feature_26', 'Aggregate_feature_27', 'Aggregate_feature_28', 'Aggregate_feature_29', 'Aggregate_feature_30', 'Aggregate_feature_31', 'Aggregate_feature_32', 'Aggregate_feature_33', 'Aggregate_feature_34', 'Aggregate_feature_35', 'Aggregate_feature_36', 'Aggregate_feature_37', 'Aggregate_feature_38', 'Aggregate_feature_39', 'Aggregate_feature_40', 'Aggregate_feature_41', 'Aggregate_feature_42', 'Aggregate_feature_43', 'Aggregate_feature_44', 'Aggregate_feature_45', 'Aggregate_feature_46', 'Aggregate_feature_47', 'Aggregate_feature_48', 'Aggregate_feature_49', 'Aggregate_feature_50', 'Aggregate_feature_51', 'Aggregate_feature_52', 'Aggregate_feature_53', 'Aggregate_feature_54', 'Aggregate_feature_55', 'Aggregate_feature_56', 'Aggregate_feature_57', 'Aggregate_feature_58', 'Aggregate_feature_59', 'Aggregate_feature_60', 'Aggregate_feature_61', 'Aggregate_feature_62', 'Aggregate_feature_63', 'Aggregate_feature_64', 'Aggregate_feature_65', 'Aggregate_feature_66', 'Aggregate_feature_67', 'Aggregate_feature_68', 'Aggregate_feature_69', 'Aggregate_feature_70', 'Aggregate_feature_71', 'Aggregate_feature_72', 'in_txs_degree', 'out_txs_degree', 'total_BTC', 'fees', 'size', 'num_input_addresses', 'num_output_addresses', 'in_BTC_min', 'in_BTC_max', 'in_BTC_mean', 'in_BTC_median', 'in_BTC_total', 'out_BTC_min', 'out_BTC_max', 'out_BTC_mean', 'out_BTC_median', 'out_BTC_total']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = graphlet_dataset.GraphletDataset(train_graphlets, G1, labeled_only=True)\n",
    "train_dataset.save_dataset(\"graphlet_datasets/tx_graphlet_train_dataset.pt\")\n",
    "\n",
    "val_dataset = graphlet_dataset.GraphletDataset(val_graphlets, G2, labeled_only=True)\n",
    "val_dataset.save_dataset(\"graphlet_datasets/tx_graphlet_val_dataset.pt\")\n",
    "\n",
    "test_dataset = graphlet_dataset.GraphletDataset(test_graphlets, G3, labeled_only=True)\n",
    "test_dataset.save_dataset(\"graphlet_datasets/tx_graphlet_test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af4549",
   "metadata": {},
   "source": [
    "## Loading datasets from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c665ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = graphlet_dataset.load_dataset(\"graphlet_datasets/tx_graphlet_train_dataset.pt\")\n",
    "# val_dataset = graphlet_dataset.load_dataset(\"graphlet_datasets/tx_graphlet_val_dataset.pt\")\n",
    "# test_dataset = graphlet_dataset.load_dataset(\"graphlet_datasets/tx_graphlet_test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def5494",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m), \u001b[38;5;28mlen\u001b[39m(val_dataset), \u001b[38;5;28mlen\u001b[39m(test_dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752ada8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 41124, 1: 353297}, {0: 38601, 1: 11522}, {0: 36808, 1: 11395})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.get_label_distribution(), val_dataset.get_label_distribution(), test_dataset.get_label_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16384, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16384, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16384, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9dd18",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f54d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.count = 0\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "            elif i == num_layers - 1:\n",
    "                self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "            else:\n",
    "                self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        # self.convs.append(GCNConv(hidden_dim, 6))\n",
    "\n",
    "        self.lns = torch.nn.ModuleList([torch.nn.LayerNorm(hidden_dim) for _ in range(num_layers - 1)])\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        if torch.isnan(x).any():\n",
    "            print(f\"NaN in conv output layer: {self.count}\")\n",
    "        for i in range(len(self.convs)):\n",
    "            x = self.convs[i](x, adj_t)\n",
    "            if torch.isnan(x).any():\n",
    "                print(f\"NaN in conv output layer: {self.count}\")\n",
    "            self.count += 1\n",
    "\n",
    "            # print(\"After Conv:\")\n",
    "            # print(x)\n",
    "            if i < len(self.lns):\n",
    "                x = self.lns[i](x)\n",
    "                # print(\"After norm:\")\n",
    "                # print(x)\n",
    "                x = torch.nn.functional.relu(x)\n",
    "                # print(\"After RELU:\")\n",
    "                # print(x)\n",
    "                x = torch.nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "                # print(x)\n",
    "        # x = self.convs[-1](x, adj_t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba05593",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mean  \n",
    "\n",
    "def train(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch.x, batch.edge_index, batch.y, batch.batch = batch.x.to(device), batch.edge_index.to(device), batch.y.to(device), batch.batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        graphlet_out = scatter_mean(out, batch.batch, dim=0)\n",
    "\n",
    "        y = batch.y\n",
    "\n",
    "        # mask = y != 2\n",
    "\n",
    "        # if mask.sum() == 0:   # skip empty batch\n",
    "        #     continue\n",
    "\n",
    "        # #Need to remap this to work with nll ?loss. Now 0 is illicit and 1 is licit.\n",
    "        # y_remapped = (y[mask]).long()\n",
    "        \n",
    "\n",
    "        preds = torch.log_softmax(graphlet_out, dim=1)\n",
    "        # print(out[mask][:5], y_remapped[:5])\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "        # print(f\"Batch {count}, Loss: {loss.item()}\")\n",
    "    # print(count, total_loss)\n",
    "    return total_loss / max(count, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    all_predictions = []\n",
    "    all_y = []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch.x, batch.edge_index, batch.y, batch.batch = batch.x.to(device), batch.edge_index.to(device), batch.y.to(device), batch.batch.to(device)\n",
    "\n",
    "        # Node-level output\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "\n",
    "        # Graphlet-level output\n",
    "        graphlet_out = scatter_mean(out, batch.batch, dim=0)  # shape [num_graphlets, num_classes]\n",
    "        y = batch.y  # graphlet labels\n",
    "\n",
    "        # Only compute loss on labeled graphlets\n",
    "        mask = (y != 2)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_remapped = y[mask].long()  # if needed, adjust mapping\n",
    "\n",
    "        masked_out = graphlet_out[mask]\n",
    "        predicted_classes = masked_out.argmax(dim=1)\n",
    "\n",
    "        all_predictions.extend(predicted_classes.cpu().tolist())\n",
    "        all_y.extend(y_remapped.cpu().tolist())\n",
    "\n",
    "\n",
    "        total_loss += loss_fn(masked_out, y_remapped).item()\n",
    "        count += 1\n",
    "    # print(\"Weighted f1:\", f1_score(all_y, all_predictions, average=\"weighted\", zero_division=0), \n",
    "    #       \"Precision:\", precision_score(all_y, all_predictions, average=\"weighted\", zero_division=0),\n",
    "        #   \"Recall:\", recall_score(all_y, all_predictions, average=\"weighted\"), zero_division=0)\n",
    "    print(\"f1:\", f1_score(all_y, all_predictions, average=None, pos_label=0, zero_division=0), \n",
    "          \"Precision:\", precision_score(all_y, all_predictions, average=None, pos_label=0, zero_division=0),\n",
    "          \"Recall:\", recall_score(all_y, all_predictions, average=None, pos_label=0, zero_division=0))\n",
    "    print(all_predictions.count(0), \"vs\", all_y.count(0), \"|\", all_predictions.count(1), \"vs\", all_y.count(1))\n",
    "    return f1_score(all_y, all_predictions, pos_label=0, zero_division=0), total_loss / max(count, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "      'device': device,\n",
    "      'num_layers': 3,\n",
    "      'hidden_dim': 64,\n",
    "      'dropout': 0.2,\n",
    "      'lr': 0.01,\n",
    "      'epochs': 30,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1043, 0.8957], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = list(train_dataset.get_label_distribution().items())\n",
    "w_ilicit = dist[0][1] / (dist[0][1] + dist[1][1])\n",
    "w_licit = dist[1][1] / (dist[0][1] + dist[1][1])\n",
    "class_weights = torch.tensor([w_ilicit, w_licit], device=device)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8816aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "model = GCN(183, #hardcoded for now\n",
    "            args[\"hidden_dim\"],\n",
    "            2,   #hardcoded for now\n",
    "            args[\"num_layers\"],\n",
    "            args[\"dropout\"]\n",
    "            ).to(args[\"device\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "\n",
    "loss_fn = NLLLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007974ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bcc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: [0.         0.37381783] Precision: [0.         0.22987451] Recall: [0. 1.]\n",
      "0 vs 38601 | 50123 vs 11522\n",
      "Epoch: 1/30 | Train loss: 0.09334821239113808 | Validation f1: 0.0 | Validation loss: -1.5442790985107422\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.00067333 0.37389668] Precision: [1.         0.22993414] Recall: [3.3677884e-04 1.0000000e+00]\n",
      "13 vs 38601 | 50110 vs 11522\n",
      "Epoch: 2/30 | Train loss: 0.05571753695607185 | Validation f1: 0.0006733309162479929 | Validation loss: -1.5651754140853882\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.63594373 0.52554912] Precision: [0.99530931 0.35738391] Recall: [0.46724178 0.99262281]\n",
      "18121 vs 38601 | 32002 vs 11522\n",
      "Epoch: 3/30 | Train loss: 0.03875474013388157 | Validation f1: 0.6359437255385917 | Validation loss: -2.1255704164505005\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.87836567 0.72993029] Precision: [0.99472408 0.57943592] Recall: [0.78637859 0.98602673]\n",
      "30516 vs 38601 | 19607 vs 11522\n",
      "Epoch: 4/30 | Train loss: 0.01976971611380577 | Validation f1: 0.8783656698062705 | Validation loss: -2.7317270636558533\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.94279494 0.84287636] Precision: [0.99294907 0.74018643] Recall: [0.8974638  0.97864954]\n",
      "34889 vs 38601 | 15234 vs 11522\n",
      "Epoch: 5/30 | Train loss: 0.011100776698440314 | Validation f1: 0.9427949380868146 | Validation loss: -3.2416263818740845\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.96893489 0.90496052] Precision: [0.99058187 0.84825021] Recall: [0.94821378 0.96979691]\n",
      "36950 vs 38601 | 13173 vs 11522\n",
      "Epoch: 6/30 | Train loss: 0.005698012607172132 | Validation f1: 0.9689348916625855 | Validation loss: -3.613870322704315\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98043623 0.93690732] Precision: [0.98926631 0.91069234] Recall: [0.97176239 0.96467627]\n",
      "37918 vs 38601 | 12205 vs 11522\n",
      "Epoch: 7/30 | Train loss: 0.003247625534422696 | Validation f1: 0.9804362315241966 | Validation loss: -4.063201189041138\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98464861 0.94952951] Precision: [0.98897165 0.93607691] Recall: [0.9803632  0.96337441]\n",
      "38265 vs 38601 | 11858 vs 11522\n",
      "Epoch: 8/30 | Train loss: 0.0016958570876158775 | Validation f1: 0.984648609268077 | Validation loss: -4.477400541305542\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.9852479  0.95111876] Precision: [0.98776201 0.94316436] Recall: [0.98274656 0.95920847]\n",
      "38405 vs 38601 | 11718 vs 11522\n",
      "Epoch: 9/30 | Train loss: 0.0011923427181318403 | Validation f1: 0.9852479027608239 | Validation loss: -4.859145402908325\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98539321 0.95156499] Precision: [0.98774012 0.94412644] Recall: [0.98305743 0.95912168]\n",
      "38418 vs 38601 | 11705 vs 11522\n",
      "Epoch: 10/30 | Train loss: 0.0009004634502343833 | Validation f1: 0.9853932146613174 | Validation loss: -5.227213978767395\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98494657 0.95034305] Precision: [0.98849315 0.93922699] Recall: [0.98142535 0.96172539]\n",
      "38325 vs 38601 | 11798 vs 11522\n",
      "Epoch: 11/30 | Train loss: 0.0007631486607715488 | Validation f1: 0.9849465720302628 | Validation loss: -5.398034572601318\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98579269 0.95274673] Precision: [0.98744541 0.94747232] Recall: [0.98414549 0.95808019]\n",
      "38472 vs 38601 | 11651 vs 11522\n",
      "Epoch: 12/30 | Train loss: 0.000769753900822252 | Validation f1: 0.9857926900470982 | Validation loss: -5.331012725830078\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98501449 0.95052564] Precision: [0.98836724 0.9399983 ] Recall: [0.98168441 0.96129144]\n",
      "38340 vs 38601 | 11783 vs 11522\n",
      "Epoch: 13/30 | Train loss: 0.0006107563397381454 | Validation f1: 0.9850144916234518 | Validation loss: -5.583500981330872\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98504595 0.95036622] Precision: [0.98717315 0.94361739] Recall: [0.9829279  0.95721229]\n",
      "38435 vs 38601 | 11688 vs 11522\n",
      "Epoch: 14/30 | Train loss: 0.0004915493831504136 | Validation f1: 0.9850459525416688 | Validation loss: -5.742997527122498\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98469978 0.94952614] Precision: [0.98823253 0.93845893] Recall: [0.9811922  0.96085749]\n",
      "38326 vs 38601 | 11797 vs 11522\n",
      "Epoch: 15/30 | Train loss: 0.00040577315201517194 | Validation f1: 0.9846997803112041 | Validation loss: -5.7855544090271\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98463137 0.9491642 ] Precision: [0.98754365 0.93999489] Recall: [0.98173622 0.95851415]\n",
      "38374 vs 38601 | 11749 vs 11522\n",
      "Epoch: 16/30 | Train loss: 0.0004169657023157924 | Validation f1: 0.9846313738226697 | Validation loss: -5.893099308013916\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98547036 0.9518316 ] Precision: [0.98786901 0.94423093] Recall: [0.98308334 0.95955563]\n",
      "38414 vs 38601 | 11709 vs 11522\n",
      "Epoch: 17/30 | Train loss: 0.0003901113840402104 | Validation f1: 0.985470362916315 | Validation loss: -5.916099667549133\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98566517 0.95229049] Precision: [0.9871635  0.94750408] Recall: [0.98417139 0.9571255 ]\n",
      "38484 vs 38601 | 11639 vs 11522\n",
      "Epoch: 18/30 | Train loss: 0.0004459327331278473 | Validation f1: 0.9856651748070312 | Validation loss: -6.120464324951172\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98396139 0.94723779] Precision: [0.98813878 0.93424496] Recall: [0.97981918 0.96059712]\n",
      "38276 vs 38601 | 11847 vs 11522\n",
      "Epoch: 19/30 | Train loss: 0.0003508607757976279 | Validation f1: 0.9839613928743317 | Validation loss: -6.090072512626648\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98460179 0.94911761] Precision: [0.98774638 0.93923685] Recall: [0.98147716 0.95920847]\n",
      "38356 vs 38601 | 11767 vs 11522\n",
      "Epoch: 20/30 | Train loss: 0.0003174982630298473 | Validation f1: 0.9846017906103408 | Validation loss: -6.2291306257247925\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98493377 0.95029804] Precision: [0.98846736 0.93922184] Recall: [0.98142535 0.9616386 ]\n",
      "38326 vs 38601 | 11797 vs 11522\n",
      "Epoch: 21/30 | Train loss: 0.0002771500594099052 | Validation f1: 0.9849337683778128 | Validation loss: -6.072258234024048\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "f1: [0.98439654 0.94858612] Precision: [0.98819997 0.93670672] Recall: [0.98062226 0.9607707 ]\n",
      "38305 vs 38601 | 11818 vs 11522\n",
      "Epoch: 22/30 | Train loss: 0.0003180130766122602 | Validation f1: 0.9843965360309989 | Validation loss: -6.359277725219727\n",
      "-------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m----> 7\u001b[0m     train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     val_f1, val_loss \u001b[38;5;241m=\u001b[39m test(model, val_loader, loss_fn)\n\u001b[0;32m     10\u001b[0m     test_losses\u001b[38;5;241m.\u001b[39mappend(train_result)\n",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m      5\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      9\u001b[0m     batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39my, batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch_geometric\\data\\collate.py:109\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch_geometric\\data\\collate.py:171\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    169\u001b[0m     incs \u001b[38;5;241m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m         values \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    172\u001b[0m             value \u001b[38;5;241m+\u001b[39m inc\u001b[38;5;241m.\u001b[39mto(value\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, incs)\n\u001b[0;32m    174\u001b[0m         ]\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     incs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y2\\s1\\MLG\\MLG\\Project\\.venv\\lib\\site-packages\\torch_geometric\\data\\collate.py:171\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m     incs \u001b[38;5;241m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m         values \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    172\u001b[0m             value \u001b[38;5;241m+\u001b[39m inc\u001b[38;5;241m.\u001b[39mto(value\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, incs)\n\u001b[0;32m    174\u001b[0m         ]\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     incs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(args[\"epochs\"]):\n",
    "    train_result = train(model, train_loader, optimizer, loss_fn)\n",
    "    val_f1, val_loss = test(model, val_loader, loss_fn)\n",
    "\n",
    "    test_losses.append(train_result)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # if epoch % 10 == 0:\n",
    "    print(f\"Epoch: {epoch+1}/{args['epochs']} | Train loss: {train_result} | Validation f1: {val_f1} | Validation loss: {val_loss}\")\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18c66438310>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.lineplot(x=range(len(test_losses)), y=test_losses, label=\"Test loss\")\n",
    "sns.lineplot(x=range(len(test_losses)), y=val_losses, label=\"Val loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_more_metrics(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    all_predictions = []\n",
    "    all_y = []\n",
    "    all_probs = []  # for ROC-AUC\n",
    "\n",
    "    for batch in loader:\n",
    "        batch.x, batch.edge_index, batch.y, batch.batch = \\\n",
    "            batch.x.to(device), batch.edge_index.to(device), batch.y.to(device), batch.batch.to(device)\n",
    "\n",
    "        # Node-level output\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "\n",
    "        # Graphlet-level output\n",
    "        graphlet_out = scatter_mean(out, batch.batch, dim=0)  # [num_graphlets, num_classes]\n",
    "        y = batch.y  # graphlet labels\n",
    "\n",
    "        # Only compute loss on labeled graphlets\n",
    "        mask = (y != 2)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_remapped = y[mask].long()\n",
    "        masked_out = graphlet_out[mask]\n",
    "\n",
    "        probs = torch.softmax(masked_out, dim=1)  # probabilities\n",
    "        predicted_classes = masked_out.argmax(dim=1)\n",
    "\n",
    "        all_predictions.extend(predicted_classes.cpu().tolist())\n",
    "        all_y.extend(y_remapped.cpu().tolist())\n",
    "        all_probs.extend(probs.cpu().tolist())\n",
    "\n",
    "        total_loss += loss_fn(masked_out, y_remapped).item()\n",
    "        count += 1\n",
    "\n",
    "    # Convert to tensors/numpy for sklearn\n",
    "    import numpy as np\n",
    "    all_y = np.array(all_y)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Metrics\n",
    "    f1 = f1_score(all_y, all_predictions, average=None, zero_division=0)\n",
    "    precision = precision_score(all_y, all_predictions, average=None, zero_division=0)\n",
    "    recall = recall_score(all_y, all_predictions, average=None, zero_division=0)\n",
    "    accuracy = accuracy_score(all_y, all_predictions)\n",
    "\n",
    "    # ROC-AUC (only works for binary)\n",
    "    if all_probs.shape[1] == 2:\n",
    "        roc_auc = roc_auc_score(all_y, all_probs[:,0])  # positive class = 0\n",
    "    else:\n",
    "        roc_auc = None\n",
    "\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    if roc_auc is not None:\n",
    "        print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "    print(all_predictions.tolist().count(0), \"vs\", all_y.tolist().count(0),\n",
    "          \"|\", all_predictions.tolist().count(1), \"vs\", all_y.tolist().count(1))\n",
    "\n",
    "    return f1, accuracy, roc_auc, total_loss / max(count, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d8386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.97537534 0.92022867]\n",
      "Precision: [0.97471377 0.9222565 ]\n",
      "Recall: [0.97603782 0.91820974]\n",
      "Accuracy: 0.9623674875007779\n",
      "ROC-AUC: 0.9684984289047949\n",
      "36858 vs 36808 | 11345 vs 11395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.97537534, 0.92022867]),\n",
       " 0.9623674875007779,\n",
       " 0.9684984289047949,\n",
       " -6.087886492411296)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_more_metrics(model, test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebbc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48203, 394421)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef30c7",
   "metadata": {},
   "source": [
    "Test new vs old GraphletDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f67f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import to_networkx\n",
    "\n",
    "# test_old = graphlet_dataset.load_dataset(\"graphlet_datasets/tx_graphlet_test_dataset.pt\")\n",
    "# test_dataset = graphlet_dataset.load_dataset(\"graphlet_datasets/tx_graphlet_test_dataset_new.pt\")\n",
    "\n",
    "# for i in range(len(test_old.data_list)):\n",
    "#     d1 = test_old.data_list[0]\n",
    "#     d2 = test_dataset.data_list[0]\n",
    "\n",
    "#     d1_ = to_networkx(d1)\n",
    "#     d2_ = to_networkx(d2)\n",
    "#     if not nx.is_isomorphic(d1_, d2_):\n",
    "#         print(\"Not isomorphic\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
